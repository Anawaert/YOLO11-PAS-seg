# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from ultralytics.engine.predictor import BasePredictor
from ultralytics.engine.results import Results
from ultralytics.utils import ops


class DetectionPredictor(BasePredictor):
    """
    A class extending the BasePredictor class for prediction based on a detection model.

    This predictor specializes in object detection tasks, processing model outputs into meaningful detection results
    with bounding boxes and class predictions.

    ä¸€ä¸ªæ‰©å±•äº† BasePredictor ç±»çš„ç±»ï¼Œç”¨äºåŸºäºæ£€æµ‹æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚

    è¯¥é¢„æµ‹å™¨ä¸“é—¨å¤„ç†ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œå°†æ¨¡å‹è¾“å‡ºå¤„ç†ä¸ºæœ‰æ„ä¹‰çš„æ£€æµ‹ç»“æœï¼ŒåŒ…æ‹¬è¾¹ç•Œæ¡†å’Œç±»åˆ«é¢„æµ‹ã€‚

    Attributes:
        args (namespace): Configuration arguments for the predictor. é¢„æµ‹å™¨çš„é…ç½®å‚æ•°ã€‚
        model (nn.Module): The detection model used for inference. ç”¨äºæ¨ç†çš„æ£€æµ‹æ¨¡å‹ã€‚
        batch (List): Batch of images and metadata for processing. ç”¨äºå¤„ç†çš„å›¾åƒå’Œå…ƒæ•°æ®æ‰¹æ¬¡ã€‚

    Methods:
        postprocess: Process raw model predictions into detection results. å°†åŸå§‹æ¨¡å‹é¢„æµ‹å¤„ç†ä¸ºæ£€æµ‹ç»“æœã€‚
        construct_results: Build Results objects from processed predictions. ä»å¤„ç†åçš„é¢„æµ‹ä¸­æ„å»º Results å¯¹è±¡ã€‚
        construct_result: Create a single Result object from a prediction. ä»é¢„æµ‹ä¸­åˆ›å»ºå•ä¸ª Result å¯¹è±¡ã€‚

    Examples:
        >>> from ultralytics.utils import ASSETS
        >>> from ultralytics.models.yolo.detect import DetectionPredictor
        >>> args = dict(model="yolo11n.pt", source=ASSETS)
        >>> predictor = DetectionPredictor(overrides=args)
        >>> predictor.predict_cli()
    """

    def postprocess(self, preds, img, orig_imgs, **kwargs):
        """
        Post-processes predictions and returns a list of Results objects.

        åå¤„ç†é¢„æµ‹ç»“æœå¹¶è¿”å› Results å¯¹è±¡åˆ—è¡¨ã€‚
        """
        preds = ops.non_max_suppression(
            preds,
            self.args.conf,
            self.args.iou,
            self.args.classes,
            self.args.agnostic_nms,
            max_det=self.args.max_det,
            nc=len(self.model.names),
            end2end=getattr(self.model, "end2end", False),
            rotated=self.args.task == "obb",
        )

        if not isinstance(orig_imgs, list):  # input images are a torch.Tensor, not a list - è¾“å…¥å›¾åƒæ˜¯ torch.Tensorï¼Œè€Œä¸æ˜¯åˆ—è¡¨
            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)

        return self.construct_results(preds, img, orig_imgs, **kwargs)

    def construct_results(self, preds, img, orig_imgs):
        """
        Construct a list of Results objects from model predictions.

        ä»æ¨¡å‹é¢„æµ‹ä¸­æ„å»º Results å¯¹è±¡åˆ—è¡¨ã€‚

        Args:
            preds (List[torch.Tensor]): List of predicted bounding boxes and scores for each image. æ¯ä¸ªå›¾åƒçš„é¢„æµ‹è¾¹ç•Œæ¡†å’Œåˆ†æ•°åˆ—è¡¨ã€‚
            img (torch.Tensor): Batch of preprocessed images used for inference. ç”¨äºæ¨ç†çš„é¢„å¤„ç†å›¾åƒæ‰¹æ¬¡ã€‚
            orig_imgs (List[np.ndarray]): List of original images before preprocessing. é¢„å¤„ç†å‰çš„åŸå§‹å›¾åƒåˆ—è¡¨ã€‚

        Returns:
            (List[Results]): List of Results objects containing detection information for each image. åŒ…å«æ¯ä¸ªå›¾åƒçš„æ£€æµ‹ä¿¡æ¯çš„ Results å¯¹è±¡åˆ—è¡¨ã€‚
        """
        return [
            self.construct_result(pred, img, orig_img, img_path)
            for pred, orig_img, img_path in zip(preds, orig_imgs, self.batch[0])
        ]

    def construct_result(self, pred, img, orig_img, img_path):
        """
        Construct a single Results object from one image prediction.

        ä»ä¸€ä¸ªå›¾åƒé¢„æµ‹ä¸­æ„å»ºå•ä¸ª Results å¯¹è±¡ã€‚

        Args:
            pred (torch.Tensor): Predicted boxes and scores with shape (N, 6) where N is the number of detections. å…·æœ‰å½¢çŠ¶ (N, 6) çš„é¢„æµ‹è¾¹ç•Œæ¡†å’Œåˆ†æ•°ï¼Œå…¶ä¸­ N æ˜¯æ£€æµ‹æ•°é‡ã€‚
            img (torch.Tensor): Preprocessed image tensor used for inference. ç”¨äºæ¨ç†çš„é¢„å¤„ç†å›¾åƒå¼ é‡ã€‚
            orig_img (np.ndarray): Original image before preprocessing. é¢„å¤„ç†å‰çš„åŸå§‹å›¾åƒã€‚
            img_path (str): Path to the original image file. åŸå§‹å›¾åƒæ–‡ä»¶çš„è·¯å¾„ã€‚

        Returns:
            (Results): Results object containing the original image, image path, class names, and scaled bounding boxes. åŒ…å«åŸå§‹å›¾åƒã€å›¾åƒè·¯å¾„ã€ç±»åˆ«åç§°å’Œç¼©æ”¾è¾¹ç•Œæ¡†çš„ Results å¯¹è±¡ã€‚
        """
        pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)
        return Results(orig_img, path=img_path, names=self.model.names, boxes=pred[:, :6])

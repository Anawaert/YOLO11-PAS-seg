# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import math
import random
from copy import copy

import numpy as np
import torch.nn as nn

from ultralytics.data import build_dataloader, build_yolo_dataset
from ultralytics.engine.trainer import BaseTrainer
from ultralytics.models import yolo
from ultralytics.nn.tasks import DetectionModel
from ultralytics.utils import LOGGER, RANK
from ultralytics.utils.plotting import plot_images, plot_labels, plot_results
from ultralytics.utils.torch_utils import de_parallel, torch_distributed_zero_first


class DetectionTrainer(BaseTrainer):
    """
    A class extending the BaseTrainer class for training based on a detection model.

    This trainer specializes in object detection tasks, handling the specific requirements for training YOLO models
    for object detection.

    ä¸€ä¸ªæ‰©å±•äº† BaseTrainer ç±»çš„ç±»ï¼Œç”¨äºåŸºäºæ£€æµ‹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚

    è¯¥è®­ç»ƒå™¨ä¸“é—¨å¤„ç†ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œå¤„ç†è®­ç»ƒ YOLO æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹çš„ç‰¹å®šè¦æ±‚ã€‚

    Attributes:
        model (DetectionModel): The YOLO detection model being trained. æ­£åœ¨è®­ç»ƒçš„ YOLO æ£€æµ‹æ¨¡å‹ã€‚
        data (Dict): Dictionary containing dataset information including class names and number of classes. åŒ…å«æ•°æ®é›†ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬ç±»åå’Œç±»åˆ«æ•°é‡ã€‚
        loss_names (Tuple[str]): Names of the loss components used in training (box_loss, cls_loss, dfl_loss). ç”¨äºè®­ç»ƒçš„æŸå¤±ç»„ä»¶çš„åç§°ï¼ˆbox_lossã€cls_lossã€dfl_lossï¼‰ã€‚

    Methods:
        build_dataset: Build YOLO dataset for training or validation. æ„å»ºç”¨äºè®­ç»ƒæˆ–éªŒè¯çš„ YOLO æ•°æ®é›†ã€‚
        get_dataloader: Construct and return dataloader for the specified mode. æ„å»ºå¹¶è¿”å›æŒ‡å®šæ¨¡å¼çš„æ•°æ®åŠ è½½å™¨ã€‚
        preprocess_batch: Preprocess a batch of images by scaling and converting to float. é€šè¿‡ç¼©æ”¾å’Œè½¬æ¢ä¸ºæµ®ç‚¹æ•°å¯¹å›¾åƒæ‰¹æ¬¡è¿›è¡Œé¢„å¤„ç†ã€‚
        set_model_attributes: Set model attributes based on dataset information. æ ¹æ®æ•°æ®é›†ä¿¡æ¯è®¾ç½®æ¨¡å‹å±æ€§ã€‚
        get_model: Return a YOLO detection model. è¿”å›ä¸€ä¸ª YOLO æ£€æµ‹æ¨¡å‹ã€‚
        get_validator: Return a validator for model evaluation. è¿”å›ç”¨äºæ¨¡å‹è¯„ä¼°çš„éªŒè¯å™¨ã€‚
        label_loss_items: Return a loss dictionary with labeled training loss items. è¿”å›å¸¦æœ‰æ ‡è®°çš„è®­ç»ƒæŸå¤±é¡¹çš„æŸå¤±å­—å…¸ã€‚
        progress_string: Return a formatted string of training progress. è¿”å›è®­ç»ƒè¿›åº¦çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚
        plot_training_samples: Plot training samples with their annotations. ç»˜åˆ¶å¸¦æœ‰æ³¨é‡Šçš„è®­ç»ƒæ ·æœ¬ã€‚
        plot_metrics: Plot metrics from a CSV file. ä» CSV æ–‡ä»¶ç»˜åˆ¶æŒ‡æ ‡ã€‚
        plot_training_labels: Create a labeled training plot of the YOLO model. åˆ›å»º YOLO æ¨¡å‹çš„æ ‡è®°è®­ç»ƒå›¾ã€‚
        auto_batch: Calculate optimal batch size based on model memory requirements. æ ¹æ®æ¨¡å‹å†…å­˜éœ€æ±‚è®¡ç®—æœ€ä½³æ‰¹æ¬¡å¤§å°ã€‚

    Examples:
        >>> from ultralytics.models.yolo.detect import DetectionTrainer
        >>> args = dict(model="yolo11n.pt", data="coco8.yaml", epochs=3)
        >>> trainer = DetectionTrainer(overrides=args)
        >>> trainer.train()
    """

    def build_dataset(self, img_path, mode="train", batch=None):
        """
        Build YOLO Dataset for training or validation.

        æ„å»ºç”¨äºè®­ç»ƒæˆ–éªŒè¯çš„ YOLO æ•°æ®é›†ã€‚

        Args:
            img_path (str): Path to the folder containing images. å›¾åƒæ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
            mode (str): `train` mode or `val` mode, users are able to customize different augmentations for each mode. `train` æ¨¡å¼æˆ– `val` æ¨¡å¼ï¼Œç”¨æˆ·å¯ä»¥ä¸ºæ¯ç§æ¨¡å¼å®šåˆ¶ä¸åŒçš„å¢å¼ºã€‚
            batch (int, optional): Size of batches, this is for `rect`. æ‰¹æ¬¡å¤§å°ï¼Œè¿™æ˜¯ä¸ºäº† `rect`ã€‚

        Returns:
            (Dataset): YOLO dataset object configured for the specified mode. é…ç½®ä¸ºæŒ‡å®šæ¨¡å¼çš„ YOLO æ•°æ®é›†å¯¹è±¡ã€‚
        """
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """
        Construct and return dataloader for the specified mode.

        æ„å»ºå¹¶è¿”å›æŒ‡å®šæ¨¡å¼çš„æ•°æ®åŠ è½½å™¨ã€‚

        Args:
            dataset_path (str): Path to the dataset. æ•°æ®é›†çš„è·¯å¾„ã€‚
            batch_size (int): Number of images per batch. æ¯æ‰¹å›¾åƒçš„æ•°é‡ã€‚
            rank (int): Process rank for distributed training. åˆ†å¸ƒå¼è®­ç»ƒçš„è¿›ç¨‹ç­‰çº§ã€‚
            mode (str): 'train' for training dataloader, 'val' for validation dataloader. 'train' ç”¨äºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œ'val' ç”¨äºéªŒè¯æ•°æ®åŠ è½½å™¨ã€‚

        Returns:
            (DataLoader): PyTorch dataloader object. PyTorch æ•°æ®åŠ è½½å™¨å¯¹è±¡ã€‚
        """
        assert mode in {"train", "val"}, f"Mode must be 'train' or 'val', not {mode}."
        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP - å¦‚æœæ˜¯ DDPï¼Œåˆ™ä»…åˆå§‹åŒ–æ•°æ®é›† *.cache ä¸€æ¬¡
            dataset = self.build_dataset(dataset_path, mode, batch_size)
        shuffle = mode == "train"
        if getattr(dataset, "rect", False) and shuffle:
            LOGGER.warning("WARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False")
            shuffle = False
        workers = self.args.workers if mode == "train" else self.args.workers * 2
        return build_dataloader(dataset, batch_size, workers, shuffle, rank)  # return dataloader - è¿”å›æ•°æ®åŠ è½½å™¨

    def preprocess_batch(self, batch):
        """
        Preprocess a batch of images by scaling and converting to float.

        é€šè¿‡ç¼©æ”¾å’Œè½¬æ¢ä¸ºæµ®ç‚¹æ•°å¯¹å›¾åƒæ‰¹æ¬¡è¿›è¡Œé¢„å¤„ç†ã€‚

        Args:
            batch (Dict): Dictionary containing batch data with 'img' tensor. åŒ…å« 'img' å¼ é‡çš„æ‰¹æ•°æ®å­—å…¸ã€‚

        Returns:
            (Dict): Preprocessed batch with normalized images. å…·æœ‰å½’ä¸€åŒ–å›¾åƒçš„é¢„å¤„ç†æ‰¹æ¬¡ã€‚
        """
        batch["img"] = batch["img"].to(self.device, non_blocking=True).float() / 255
        if self.args.multi_scale:
            imgs = batch["img"]
            sz = (
                random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                // self.stride
                * self.stride
            )  # size
            sf = sz / max(imgs.shape[2:])  # scale factor - ç¼©æ”¾å› å­
            if sf != 1:
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs.shape[2:]
                ]  # new shape (stretched to gs-multiple) - æ–°å½¢çŠ¶ï¼ˆæ‹‰ä¼¸åˆ° gs çš„å€æ•°ï¼‰
                imgs = nn.functional.interpolate(imgs, size=ns, mode="bilinear", align_corners=False)
            batch["img"] = imgs
        return batch

    def set_model_attributes(self):
        """
        Set model attributes based on dataset information.

        æ ¹æ®æ•°æ®é›†ä¿¡æ¯è®¾ç½®æ¨¡å‹å±æ€§ã€‚
        """
        # Nl = de_parallel(self.model).model[-1].nl  # number of detection layers (to scale hyps) - æ£€æµ‹å±‚çš„æ•°é‡ï¼ˆç”¨äºç¼©æ”¾è¶…å‚æ•°ï¼‰
        # self.args.box *= 3 / nl  # scale to layers - ç¼©æ”¾åˆ°å±‚
        # self.args.cls *= self.data["nc"] / 80 * 3 / nl  # scale to classes and layers - ç¼©æ”¾åˆ°ç±»åˆ«å’Œå±‚
        # self.args.cls *= (self.args.imgsz / 640) ** 2 * 3 / nl  # scale to image size and layers - ç¼©æ”¾åˆ°å›¾åƒå¤§å°å’Œå±‚
        self.model.nc = self.data["nc"]  # attach number of classes to model - å°†ç±»åˆ«æ•°é‡é™„åŠ åˆ°æ¨¡å‹
        self.model.names = self.data["names"]  # attach class names to model - å°†ç±»åé™„åŠ åˆ°æ¨¡å‹
        self.model.args = self.args  # attach hyperparameters to model - å°†è¶…å‚æ•°é™„åŠ åˆ°æ¨¡å‹
        # TODO: self.model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc

    def get_model(self, cfg=None, weights=None, verbose=True):
        """
        Return a YOLO detection model.

        è¿”å›ä¸€ä¸ª YOLO æ£€æµ‹æ¨¡å‹ã€‚

        Args:
            cfg (str, optional): Path to model configuration file. æ¨¡å‹é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚
            weights (str, optional): Path to model weights. æ¨¡å‹æƒé‡çš„è·¯å¾„ã€‚
            verbose (bool): Whether to display model information. æ˜¯å¦æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ã€‚

        Returns:
            (DetectionModel): YOLO detection model. YOLO æ£€æµ‹æ¨¡å‹ã€‚
        """
        model = DetectionModel(cfg, nc=self.data["nc"], verbose=verbose and RANK == -1)
        if weights:
            model.load(weights)
        return model

    def get_validator(self):
        """

        Return a DetectionValidator for YOLO model validation.

        è¿”å›ç”¨äº YOLO æ¨¡å‹éªŒè¯çš„ DetectionValidatorã€‚
        """
        self.loss_names = "box_loss", "cls_loss", "dfl_loss"
        return yolo.detect.DetectionValidator(
            self.test_loader, save_dir=self.save_dir, args=copy(self.args), _callbacks=self.callbacks
        )

    def label_loss_items(self, loss_items=None, prefix="train"):
        """
        Return a loss dict with labeled training loss items tensor.

        è¿”å›å¸¦æœ‰æ ‡è®°çš„è®­ç»ƒæŸå¤±é¡¹å¼ é‡çš„æŸå¤±å­—å…¸ã€‚

        Args:
            loss_items (List[float], optional): List of loss values. æŸå¤±å€¼åˆ—è¡¨ã€‚
            prefix (str): Prefix for keys in the returned dictionary. è¿”å›çš„å­—å…¸ä¸­é”®çš„å‰ç¼€ã€‚

        Returns:
            (Dict | List): Dictionary of labeled loss items if loss_items is provided, otherwise list of keys. å¦‚æœæä¾›äº† loss_itemsï¼Œåˆ™è¿”å›å¸¦æœ‰æ ‡è®°çš„æŸå¤±é¡¹å­—å…¸ï¼Œå¦åˆ™è¿”å›é”®åˆ—è¡¨ã€‚
        """
        keys = [f"{prefix}/{x}" for x in self.loss_names]
        if loss_items is not None:
            loss_items = [round(float(x), 5) for x in loss_items]  # convert tensors to 5 decimal place floats - å°†å¼ é‡è½¬æ¢ä¸º 5 ä½å°æ•°æµ®ç‚¹æ•°
            return dict(zip(keys, loss_items))
        else:
            return keys

    def progress_string(self):
        """
        Return a formatted string of training progress with epoch, GPU memory, loss, instances and size.

        è¿”å›å¸¦æœ‰ epochã€GPU å†…å­˜ã€æŸå¤±ã€å®ä¾‹å’Œå¤§å°çš„è®­ç»ƒè¿›åº¦çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚
        """
        return ("\n" + "%11s" * (4 + len(self.loss_names))) % (
            "Epoch",
            "GPU_mem",
            *self.loss_names,
            "Instances",
            "Size",
        )

    def plot_training_samples(self, batch, ni):
        """
        Plot training samples with their annotations.

        ç»˜åˆ¶å¸¦æœ‰æ³¨é‡Šçš„è®­ç»ƒæ ·æœ¬ã€‚

        Args:
            batch (Dict): Dictionary containing batch data. åŒ…å«æ‰¹æ•°æ®çš„å­—å…¸ã€‚
            ni (int): Number of iterations. è¿­ä»£æ¬¡æ•°ã€‚
        """
        plot_images(
            images=batch["img"],
            batch_idx=batch["batch_idx"],
            cls=batch["cls"].squeeze(-1),
            bboxes=batch["bboxes"],
            paths=batch["im_file"],
            fname=self.save_dir / f"train_batch{ni}.jpg",
            on_plot=self.on_plot,
        )

    def plot_metrics(self):
        """
        Plot metrics from a CSV file.

        ä» CSV æ–‡ä»¶ç»˜åˆ¶æŒ‡æ ‡ã€‚
        """
        plot_results(file=self.csv, on_plot=self.on_plot)  # save results.png - ä¿å­˜ results.png

    def plot_training_labels(self):
        """
        Create a labeled training plot of the YOLO model.

        åˆ›å»º YOLO æ¨¡å‹çš„æ ‡è®°è®­ç»ƒå›¾ã€‚
        """
        boxes = np.concatenate([lb["bboxes"] for lb in self.train_loader.dataset.labels], 0)
        cls = np.concatenate([lb["cls"] for lb in self.train_loader.dataset.labels], 0)
        plot_labels(boxes, cls.squeeze(), names=self.data["names"], save_dir=self.save_dir, on_plot=self.on_plot)

    def auto_batch(self):
        """
        Get optimal batch size by calculating memory occupation of model.

        é€šè¿‡è®¡ç®—æ¨¡å‹çš„å†…å­˜å ç”¨æ¥è·å–æœ€ä½³æ‰¹æ¬¡å¤§å°ã€‚

        Returns:
            (int): Optimal batch size. æœ€ä½³æ‰¹æ¬¡å¤§å°ã€‚
        """
        train_dataset = self.build_dataset(self.trainset, mode="train", batch=16)
        max_num_obj = max(len(label["cls"]) for label in train_dataset.labels) * 4  # 4 for mosaic augmentation - 4 ç”¨äºé©¬èµ›å…‹å¢å¼º
        return super().auto_batch(max_num_obj)

# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

import torch
import torch.nn as nn
import torch.nn.functional as F

from ultralytics.utils.loss import FocalLoss, VarifocalLoss
from ultralytics.utils.metrics import bbox_iou

from .ops import HungarianMatcher


class DETRLoss(nn.Module):
    """
    DETR (DEtection TRansformer) Loss class for calculating various loss components.

    This class computes classification loss, bounding box loss, GIoU loss, and optionally auxiliary losses for the
    DETR object detection model.

    DETRï¼ˆDEtection TRansformerï¼‰æŸå¤±ç±»ï¼Œç”¨äºŽè®¡ç®—å„ç§æŸå¤±ç»„ä»¶ã€‚

    è¯¥ç±»è®¡ç®—åˆ†ç±»æŸå¤±ã€è¾¹ç•Œæ¡†æŸå¤±ã€GIoU æŸå¤±ï¼Œå¹¶å¯é€‰åœ°è®¡ç®— DETR ç›®æ ‡æ£€æµ‹æ¨¡åž‹çš„è¾…åŠ©æŸå¤±ã€‚

    Attributes:
        nc (int): Number of classes. ä¸åŒæŸå¤±ç»„ä»¶çš„ç³»æ•°ã€‚
        loss_gain (Dict): Coefficients for different loss components. ä¸åŒæŸå¤±ç»„ä»¶çš„ç³»æ•°ã€‚
        aux_loss (bool): Whether to compute auxiliary losses. æ˜¯å¦è®¡ç®—è¾…åŠ©æŸå¤±ã€‚
        use_fl (bool): Whether to use FocalLoss. æ˜¯å¦ä½¿ç”¨ FocalLossã€‚
        use_vfl (bool): Whether to use VarifocalLoss. æ˜¯å¦ä½¿ç”¨ VarifocalLossã€‚
        use_uni_match (bool): Whether to use a fixed layer for auxiliary branch label assignment. æ˜¯å¦ä½¿ç”¨å›ºå®šå±‚è¿›è¡Œè¾…åŠ©åˆ†æ”¯æ ‡ç­¾åˆ†é…ã€‚
        uni_match_ind (int): Index of fixed layer to use if use_uni_match is True. å¦‚æžœ use_uni_match ä¸º Trueï¼Œåˆ™ä½¿ç”¨å›ºå®šå±‚çš„ç´¢å¼•ã€‚
        matcher (HungarianMatcher): Object to compute matching cost and indices. ç”¨äºŽè®¡ç®—åŒ¹é…æˆæœ¬å’Œç´¢å¼•çš„å¯¹è±¡ã€‚
        fl (FocalLoss | None): Focal Loss object if use_fl is True, otherwise None. å¦‚æžœ use_fl ä¸º Trueï¼Œåˆ™ä¸º Focal Loss å¯¹è±¡ï¼Œå¦åˆ™ä¸º Noneã€‚
        vfl (VarifocalLoss | None): Varifocal Loss object if use_vfl is True, otherwise None. å¦‚æžœ use_vfl ä¸º Trueï¼Œåˆ™ä¸º Varifocal Loss å¯¹è±¡ï¼Œå¦åˆ™ä¸º Noneã€‚
        device (torch.device): Device on which tensors are stored. å­˜å‚¨å¼ é‡çš„è®¾å¤‡ã€‚
    """

    def __init__(
        self, nc=80, loss_gain=None, aux_loss=True, use_fl=True, use_vfl=False, use_uni_match=False, uni_match_ind=0
    ):
        """
        Initialize DETR loss function with customizable components and gains.

        Uses default loss_gain if not provided. Initializes HungarianMatcher with preset cost gains. Supports auxiliary
        losses and various loss types.

        ä½¿ç”¨é»˜è®¤ loss_gainï¼ˆå¦‚æžœæœªæä¾›ï¼‰åˆå§‹åŒ– DETR æŸå¤±å‡½æ•°ã€‚

        ä½¿ç”¨é¢„è®¾æˆæœ¬å¢žç›Šåˆå§‹åŒ– HungarianMatcherã€‚æ”¯æŒè¾…åŠ©æŸå¤±å’Œå„ç§æŸå¤±ç±»åž‹ã€‚

        Args:
            nc (int): Number of classes. ç±»åˆ«æ•°ã€‚
            loss_gain (Dict): Coefficients for different loss components. ä¸åŒæŸå¤±ç»„ä»¶çš„ç³»æ•°ã€‚
            aux_loss (bool): Whether to use auxiliary losses from each decoder layer. æ˜¯å¦ä½¿ç”¨æ¯ä¸ªè§£ç å™¨å±‚çš„è¾…åŠ©æŸå¤±ã€‚
            use_fl (bool): Whether to use FocalLoss. æ˜¯å¦ä½¿ç”¨ FocalLossã€‚
            use_vfl (bool): Whether to use VarifocalLoss. æ˜¯å¦ä½¿ç”¨ VarifocalLossã€‚
            use_uni_match (bool): Whether to use fixed layer for auxiliary branch label assignment. æ˜¯å¦ä½¿ç”¨å›ºå®šå±‚è¿›è¡Œè¾…åŠ©åˆ†æ”¯æ ‡ç­¾åˆ†é…ã€‚
            uni_match_ind (int): Index of fixed layer for uni_match. uni_match çš„å›ºå®šå±‚ç´¢å¼•ã€‚
        """
        super().__init__()

        if loss_gain is None:
            loss_gain = {"class": 1, "bbox": 5, "giou": 2, "no_object": 0.1, "mask": 1, "dice": 1}
        self.nc = nc
        self.matcher = HungarianMatcher(cost_gain={"class": 2, "bbox": 5, "giou": 2})
        self.loss_gain = loss_gain
        self.aux_loss = aux_loss
        self.fl = FocalLoss() if use_fl else None
        self.vfl = VarifocalLoss() if use_vfl else None

        self.use_uni_match = use_uni_match
        self.uni_match_ind = uni_match_ind
        self.device = None

    def _get_loss_class(self, pred_scores, targets, gt_scores, num_gts, postfix=""):
        """
        Compute classification loss based on predictions, target values, and ground truth scores.

        æ ¹æ®é¢„æµ‹ã€ç›®æ ‡å€¼å’ŒçœŸå®žåˆ†æ•°è®¡ç®—åˆ†ç±»æŸå¤±ã€‚
        """
        # Logits: [b, query, num_classes], gt_class: list[[n, 1]]
        name_class = f"loss_class{postfix}"
        bs, nq = pred_scores.shape[:2]
        # one_hot = F.one_hot(targets, self.nc + 1)[..., :-1]  # (bs, num_queries, num_classes)
        one_hot = torch.zeros((bs, nq, self.nc + 1), dtype=torch.int64, device=targets.device)
        one_hot.scatter_(2, targets.unsqueeze(-1), 1)
        one_hot = one_hot[..., :-1]
        gt_scores = gt_scores.view(bs, nq, 1) * one_hot

        if self.fl:
            if num_gts and self.vfl:
                loss_cls = self.vfl(pred_scores, gt_scores, one_hot)
            else:
                loss_cls = self.fl(pred_scores, one_hot.float())
            loss_cls /= max(num_gts, 1) / nq
        else:
            loss_cls = nn.BCEWithLogitsLoss(reduction="none")(pred_scores, gt_scores).mean(1).sum()  # YOLO CLS loss

        return {name_class: loss_cls.squeeze() * self.loss_gain["class"]}

    def _get_loss_bbox(self, pred_bboxes, gt_bboxes, postfix=""):
        """
        Compute bounding box and GIoU losses for predicted and ground truth bounding boxes.

        è®¡ç®—é¢„æµ‹å’ŒçœŸå®žè¾¹ç•Œæ¡†çš„è¾¹ç•Œæ¡†å’Œ GIoU æŸå¤±ã€‚
        """
        # Boxes: [b, query, 4], gt_bbox: list[[n, 4]]
        name_bbox = f"loss_bbox{postfix}"
        name_giou = f"loss_giou{postfix}"

        loss = {}
        if len(gt_bboxes) == 0:
            loss[name_bbox] = torch.tensor(0.0, device=self.device)
            loss[name_giou] = torch.tensor(0.0, device=self.device)
            return loss

        loss[name_bbox] = self.loss_gain["bbox"] * F.l1_loss(pred_bboxes, gt_bboxes, reduction="sum") / len(gt_bboxes)
        loss[name_giou] = 1.0 - bbox_iou(pred_bboxes, gt_bboxes, xywh=True, GIoU=True)
        loss[name_giou] = loss[name_giou].sum() / len(gt_bboxes)
        loss[name_giou] = self.loss_gain["giou"] * loss[name_giou]
        return {k: v.squeeze() for k, v in loss.items()}

    # This function is for future RT-DETR Segment models
    # æ­¤å‡½æ•°ç”¨äºŽæœªæ¥çš„ RT-DETR Segment æ¨¡åž‹
    # def _get_loss_mask(self, masks, gt_mask, match_indices, postfix=''):
    #     # masks: [b, query, h, w], gt_mask: list[[n, H, W]]
    #     name_mask = f'loss_mask{postfix}'
    #     name_dice = f'loss_dice{postfix}'
    #
    #     loss = {}
    #     if sum(len(a) for a in gt_mask) == 0:
    #         loss[name_mask] = torch.tensor(0., device=self.device)
    #         loss[name_dice] = torch.tensor(0., device=self.device)
    #         return loss
    #
    #     num_gts = len(gt_mask)
    #     src_masks, target_masks = self._get_assigned_bboxes(masks, gt_mask, match_indices)
    #     src_masks = F.interpolate(src_masks.unsqueeze(0), size=target_masks.shape[-2:], mode='bilinear')[0]
    #     # TODO: torch does not have `sigmoid_focal_loss`, but it's not urgent since we don't use mask branch for now.
    #     loss[name_mask] = self.loss_gain['mask'] * F.sigmoid_focal_loss(src_masks, target_masks,
    #                                                                     torch.tensor([num_gts], dtype=torch.float32))
    #     loss[name_dice] = self.loss_gain['dice'] * self._dice_loss(src_masks, target_masks, num_gts)
    #     return loss

    # This function is for future RT-DETR Segment models
    # @staticmethod
    # def _dice_loss(inputs, targets, num_gts):
    #     inputs = F.sigmoid(inputs).flatten(1)
    #     targets = targets.flatten(1)
    #     numerator = 2 * (inputs * targets).sum(1)
    #     denominator = inputs.sum(-1) + targets.sum(-1)
    #     loss = 1 - (numerator + 1) / (denominator + 1)
    #     return loss.sum() / num_gts

    def _get_loss_aux(
        self,
        pred_bboxes,
        pred_scores,
        gt_bboxes,
        gt_cls,
        gt_groups,
        match_indices=None,
        postfix="",
        masks=None,
        gt_mask=None,
    ):
        """
        Get auxiliary losses for intermediate decoder layers.

        èŽ·å–ä¸­é—´è§£ç å™¨å±‚çš„è¾…åŠ©æŸå¤±ã€‚

        Args:
            pred_bboxes (torch.Tensor): Predicted bounding boxes from auxiliary layers. è¾…åŠ©å±‚çš„é¢„æµ‹è¾¹ç•Œæ¡†ã€‚
            pred_scores (torch.Tensor): Predicted scores from auxiliary layers. è¾…åŠ©å±‚çš„é¢„æµ‹åˆ†æ•°ã€‚
            gt_bboxes (torch.Tensor): Ground truth bounding boxes. çœŸå®žè¾¹ç•Œæ¡†ã€‚
            gt_cls (torch.Tensor): Ground truth classes. çœŸå®žç±»åˆ«ã€‚
            gt_groups (List[int]): Number of ground truths per image. æ¯å¼ å›¾åƒçš„çœŸå®žæ•°é‡ã€‚
            match_indices (List[tuple], optional): Pre-computed matching indices. é¢„å…ˆè®¡ç®—çš„åŒ¹é…ç´¢å¼•ã€‚
            postfix (str): String to append to loss names. é™„åŠ åˆ°æŸå¤±åç§°çš„å­—ç¬¦ä¸²ã€‚
            masks (torch.Tensor, optional): Predicted masks if using segmentation. å¦‚æžœä½¿ç”¨åˆ†å‰²ï¼Œåˆ™ä¸ºé¢„æµ‹çš„æŽ©ç ã€‚
            gt_mask (torch.Tensor, optional): Ground truth masks if using segmentation. å¦‚æžœä½¿ç”¨åˆ†å‰²ï¼Œåˆ™ä¸ºçœŸå®žæŽ©ç ã€‚

        Returns:
            (Dict): Dictionary of auxiliary losses. è¾…åŠ©æŸå¤±çš„å­—å…¸ã€‚
        """
        # NOTE: loss class, bbox, giou, mask, dice
        loss = torch.zeros(5 if masks is not None else 3, device=pred_bboxes.device)
        if match_indices is None and self.use_uni_match:
            match_indices = self.matcher(
                pred_bboxes[self.uni_match_ind],
                pred_scores[self.uni_match_ind],
                gt_bboxes,
                gt_cls,
                gt_groups,
                masks=masks[self.uni_match_ind] if masks is not None else None,
                gt_mask=gt_mask,
            )
        for i, (aux_bboxes, aux_scores) in enumerate(zip(pred_bboxes, pred_scores)):
            aux_masks = masks[i] if masks is not None else None
            loss_ = self._get_loss(
                aux_bboxes,
                aux_scores,
                gt_bboxes,
                gt_cls,
                gt_groups,
                masks=aux_masks,
                gt_mask=gt_mask,
                postfix=postfix,
                match_indices=match_indices,
            )
            loss[0] += loss_[f"loss_class{postfix}"]
            loss[1] += loss_[f"loss_bbox{postfix}"]
            loss[2] += loss_[f"loss_giou{postfix}"]
            # if masks is not None and gt_mask is not None:
            #     loss_ = self._get_loss_mask(aux_masks, gt_mask, match_indices, postfix)
            #     loss[3] += loss_[f'loss_mask{postfix}']
            #     loss[4] += loss_[f'loss_dice{postfix}']

        loss = {
            f"loss_class_aux{postfix}": loss[0],
            f"loss_bbox_aux{postfix}": loss[1],
            f"loss_giou_aux{postfix}": loss[2],
        }
        # if masks is not None and gt_mask is not None:
        #     loss[f'loss_mask_aux{postfix}'] = loss[3]
        #     loss[f'loss_dice_aux{postfix}'] = loss[4]
        return loss

    @staticmethod
    def _get_index(match_indices):
        """
        Extract batch indices, source indices, and destination indices from match indices.

        ä»ŽåŒ¹é…ç´¢å¼•ä¸­æå–æ‰¹æ¬¡ç´¢å¼•ã€æºç´¢å¼•å’Œç›®æ ‡ç´¢å¼•ã€‚

        Args:
            match_indices (List[tuple]): List of tuples containing matched indices. åŒ…å«åŒ¹é…ç´¢å¼•çš„å…ƒç»„åˆ—è¡¨ã€‚

        Returns:
            (tuple): Tuple containing (batch_idx, src_idx) and dst_idx. åŒ…å« (batch_idx, src_idx) å’Œ dst_idx çš„å…ƒç»„ã€‚
        """
        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(match_indices)])
        src_idx = torch.cat([src for (src, _) in match_indices])
        dst_idx = torch.cat([dst for (_, dst) in match_indices])
        return (batch_idx, src_idx), dst_idx

    def _get_assigned_bboxes(self, pred_bboxes, gt_bboxes, match_indices):
        """
        Assign predicted bounding boxes to ground truth bounding boxes based on match indices.

        æ ¹æ®åŒ¹é…ç´¢å¼•å°†é¢„æµ‹è¾¹ç•Œæ¡†åˆ†é…ç»™çœŸå®žè¾¹ç•Œæ¡†ã€‚

        Args:
            pred_bboxes (torch.Tensor): Predicted bounding boxes. é¢„æµ‹è¾¹ç•Œæ¡†ã€‚
            gt_bboxes (torch.Tensor): Ground truth bounding boxes. çœŸå®žè¾¹ç•Œæ¡†ã€‚
            match_indices (List[tuple]): List of tuples containing matched indices. åŒ…å«åŒ¹é…ç´¢å¼•çš„å…ƒç»„åˆ—è¡¨ã€‚

        Returns:
            (tuple): Tuple containing assigned predictions and ground truths. åŒ…å«åˆ†é…çš„é¢„æµ‹å’ŒçœŸå®žå€¼çš„å…ƒç»„ã€‚
        """
        pred_assigned = torch.cat(
            [
                t[i] if len(i) > 0 else torch.zeros(0, t.shape[-1], device=self.device)
                for t, (i, _) in zip(pred_bboxes, match_indices)
            ]
        )
        gt_assigned = torch.cat(
            [
                t[j] if len(j) > 0 else torch.zeros(0, t.shape[-1], device=self.device)
                for t, (_, j) in zip(gt_bboxes, match_indices)
            ]
        )
        return pred_assigned, gt_assigned

    def _get_loss(
        self,
        pred_bboxes,
        pred_scores,
        gt_bboxes,
        gt_cls,
        gt_groups,
        masks=None,
        gt_mask=None,
        postfix="",
        match_indices=None,
    ):
        """
        Calculate losses for a single prediction layer.

        è®¡ç®—å•ä¸ªé¢„æµ‹å±‚çš„æŸå¤±ã€‚

        Args:
            pred_bboxes (torch.Tensor): Predicted bounding boxes. é¢„æµ‹è¾¹ç•Œæ¡†ã€‚
            pred_scores (torch.Tensor): Predicted class scores. é¢„æµ‹ç±»åˆ«åˆ†æ•°ã€‚
            gt_bboxes (torch.Tensor): Ground truth bounding boxes. çœŸå®žè¾¹ç•Œæ¡†ã€‚
            gt_cls (torch.Tensor): Ground truth classes. çœŸå®žç±»åˆ«ã€‚
            gt_groups (List[int]): Number of ground truths per image. æ¯å¼ å›¾åƒçš„çœŸå®žæ•°é‡ã€‚
            masks (torch.Tensor, optional): Predicted masks if using segmentation. å¦‚æžœä½¿ç”¨åˆ†å‰²ï¼Œåˆ™ä¸ºé¢„æµ‹çš„æŽ©ç ã€‚
            gt_mask (torch.Tensor, optional): Ground truth masks if using segmentation. å¦‚æžœä½¿ç”¨åˆ†å‰²ï¼Œåˆ™ä¸ºçœŸå®žæŽ©ç ã€‚
            postfix (str): String to append to loss names. é™„åŠ åˆ°æŸå¤±åç§°çš„å­—ç¬¦ä¸²ã€‚
            match_indices (List[tuple], optional): Pre-computed matching indices. é¢„å…ˆè®¡ç®—çš„åŒ¹é…ç´¢å¼•ã€‚

        Returns:
            (Dict): Dictionary of losses. æŸå¤±çš„å­—å…¸ã€‚
        """
        if match_indices is None:
            match_indices = self.matcher(
                pred_bboxes, pred_scores, gt_bboxes, gt_cls, gt_groups, masks=masks, gt_mask=gt_mask
            )

        idx, gt_idx = self._get_index(match_indices)
        pred_bboxes, gt_bboxes = pred_bboxes[idx], gt_bboxes[gt_idx]

        bs, nq = pred_scores.shape[:2]
        targets = torch.full((bs, nq), self.nc, device=pred_scores.device, dtype=gt_cls.dtype)
        targets[idx] = gt_cls[gt_idx]

        gt_scores = torch.zeros([bs, nq], device=pred_scores.device)
        if len(gt_bboxes):
            gt_scores[idx] = bbox_iou(pred_bboxes.detach(), gt_bboxes, xywh=True).squeeze(-1)

        return {
            **self._get_loss_class(pred_scores, targets, gt_scores, len(gt_bboxes), postfix),
            **self._get_loss_bbox(pred_bboxes, gt_bboxes, postfix),
            # **(self._get_loss_mask(masks, gt_mask, match_indices, postfix) if masks is not None and gt_mask is not None else {})
        }

    def forward(self, pred_bboxes, pred_scores, batch, postfix="", **kwargs):
        """
        Calculate loss for predicted bounding boxes and scores.

        è®¡ç®—é¢„æµ‹è¾¹ç•Œæ¡†å’Œåˆ†æ•°çš„æŸå¤±ã€‚

        Args:
            pred_bboxes (torch.Tensor): Predicted bounding boxes, shape [l, b, query, 4]. é¢„æµ‹è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ [l, b, query, 4]ã€‚
            pred_scores (torch.Tensor): Predicted class scores, shape [l, b, query, num_classes]. é¢„æµ‹ç±»åˆ«åˆ†æ•°ï¼Œå½¢çŠ¶ [l, b, query, num_classes]ã€‚
            batch (Dict): Batch information containing: cls, bboxes, gt_groups. åŒ…å« clsã€bboxesã€gt_groups çš„æ‰¹æ¬¡ä¿¡æ¯ã€‚
                cls (torch.Tensor): Ground truth classes, shape [num_gts]. çœŸå®žç±»åˆ«ï¼Œå½¢çŠ¶ [num_gts]ã€‚
                bboxes (torch.Tensor): Ground truth bounding boxes, shape [num_gts, 4]. çœŸå®žè¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ [num_gts, 4]ã€‚
                gt_groups (List[int]): Number of ground truths for each image in the batch. æ‰¹æ¬¡ä¸­æ¯å¼ å›¾åƒçš„çœŸå®žæ•°é‡ã€‚
            postfix (str): Postfix for loss names. æŸå¤±åç§°çš„åŽç¼€ã€‚
            **kwargs (Any): Additional arguments, may include 'match_indices'. å…¶ä»–å‚æ•°ï¼Œå¯èƒ½åŒ…æ‹¬ 'match_indices'ã€‚

        Returns:
            (Dict): Computed losses, including main and auxiliary (if enabled). è®¡ç®—çš„æŸå¤±ï¼ŒåŒ…æ‹¬ä¸»è¦å’Œè¾…åŠ©ï¼ˆå¦‚æžœå¯ç”¨ï¼‰ã€‚

        Notes:
            Uses last elements of pred_bboxes and pred_scores for main loss, and the rest for auxiliary losses if
            self.aux_loss is True. å¦‚æžœ self.aux_loss ä¸º Trueï¼Œåˆ™ä½¿ç”¨ pred_bboxes å’Œ pred_scores çš„æœ€åŽä¸€ä¸ªå…ƒç´ è¿›è¡Œä¸»è¦æŸå¤±ï¼Œ
        """
        self.device = pred_bboxes.device
        match_indices = kwargs.get("match_indices", None)
        gt_cls, gt_bboxes, gt_groups = batch["cls"], batch["bboxes"], batch["gt_groups"]

        total_loss = self._get_loss(
            pred_bboxes[-1], pred_scores[-1], gt_bboxes, gt_cls, gt_groups, postfix=postfix, match_indices=match_indices
        )

        if self.aux_loss:
            total_loss.update(
                self._get_loss_aux(
                    pred_bboxes[:-1], pred_scores[:-1], gt_bboxes, gt_cls, gt_groups, match_indices, postfix
                )
            )

        return total_loss


class RTDETRDetectionLoss(DETRLoss):
    """
    Real-Time DeepTracker (RT-DETR) Detection Loss class that extends the DETRLoss.

    This class computes the detection loss for the RT-DETR model, which includes the standard detection loss as well as
    an additional denoising training loss when provided with denoising metadata.

    æ‰©å±• DETRLoss çš„å®žæ—¶ DeepTrackerï¼ˆRT-DETRï¼‰æ£€æµ‹æŸå¤±ç±»ã€‚

    è¯¥ç±»è®¡ç®— RT-DETR æ¨¡åž‹çš„æ£€æµ‹æŸå¤±ï¼Œå…¶ä¸­åŒ…æ‹¬æ ‡å‡†æ£€æµ‹æŸå¤±ä»¥åŠåœ¨æä¾›åŽ»å™ªå…ƒæ•°æ®æ—¶çš„é¢å¤–åŽ»å™ªè®­ç»ƒæŸå¤±ã€‚
    """

    def forward(self, preds, batch, dn_bboxes=None, dn_scores=None, dn_meta=None):
        """
        Forward pass to compute detection loss with optional denoising loss.

        å‰å‘ä¼ é€’ä»¥è®¡ç®—æ£€æµ‹æŸå¤±å’Œå¯é€‰çš„åŽ»å™ªæŸå¤±ã€‚

        Args:
            preds (tuple): Tuple containing predicted bounding boxes and scores. åŒ…å«é¢„æµ‹è¾¹ç•Œæ¡†å’Œåˆ†æ•°çš„å…ƒç»„ã€‚
            batch (Dict): Batch data containing ground truth information. åŒ…å«çœŸå®žä¿¡æ¯çš„æ‰¹æ¬¡æ•°æ®ã€‚
            dn_bboxes (torch.Tensor, optional): Denoising bounding boxes. åŽ»å™ªè¾¹ç•Œæ¡†ã€‚
            dn_scores (torch.Tensor, optional): Denoising scores. åŽ»å™ªåˆ†æ•°ã€‚
            dn_meta (Dict, optional): Metadata for denoising. åŽ»å™ªçš„å…ƒæ•°æ®ã€‚

        Returns:
            (Dict): Dictionary containing total loss and denoising loss if applicable. åŒ…å«æ€»æŸå¤±å’ŒåŽ»å™ªæŸå¤±ï¼ˆå¦‚æžœé€‚ç”¨ï¼‰çš„å­—å…¸ã€‚
        """
        pred_bboxes, pred_scores = preds
        total_loss = super().forward(pred_bboxes, pred_scores, batch)

        # Check for denoising metadata to compute denoising training loss
        # æ£€æŸ¥åŽ»å™ªå…ƒæ•°æ®ä»¥è®¡ç®—åŽ»å™ªè®­ç»ƒæŸå¤±
        if dn_meta is not None:
            dn_pos_idx, dn_num_group = dn_meta["dn_pos_idx"], dn_meta["dn_num_group"]
            assert len(batch["gt_groups"]) == len(dn_pos_idx)

            # Get the match indices for denoising
            # èŽ·å–åŽ»å™ªçš„åŒ¹é…ç´¢å¼•
            match_indices = self.get_dn_match_indices(dn_pos_idx, dn_num_group, batch["gt_groups"])

            # Compute the denoising training loss
            # è®¡ç®—åŽ»å™ªè®­ç»ƒæŸå¤±
            dn_loss = super().forward(dn_bboxes, dn_scores, batch, postfix="_dn", match_indices=match_indices)
            total_loss.update(dn_loss)
        else:
            # If no denoising metadata is provided, set denoising loss to zero
            # å¦‚æžœæœªæä¾›åŽ»å™ªå…ƒæ•°æ®ï¼Œåˆ™å°†åŽ»å™ªæŸå¤±è®¾ç½®ä¸ºé›¶
            total_loss.update({f"{k}_dn": torch.tensor(0.0, device=self.device) for k in total_loss.keys()})

        return total_loss

    @staticmethod
    def get_dn_match_indices(dn_pos_idx, dn_num_group, gt_groups):
        """
        Get match indices for denoising.

        èŽ·å–åŽ»å™ªçš„åŒ¹é…ç´¢å¼•ã€‚

        Args:
            dn_pos_idx (List[torch.Tensor]): List of tensors containing positive indices for denoising. åŒ…å«åŽ»å™ªæ­£ç´¢å¼•çš„å¼ é‡åˆ—è¡¨ã€‚
            dn_num_group (int): Number of denoising groups. åŽ»å™ªç»„çš„æ•°é‡ã€‚
            gt_groups (List[int]): List of integers representing number of ground truths per image. è¡¨ç¤ºæ¯å¼ å›¾åƒçš„çœŸå®žæ•°é‡çš„æ•´æ•°åˆ—è¡¨ã€‚

        Returns:
            (List[tuple]): List of tuples containing matched indices for denoising. åŒ…å«åŽ»å™ªåŒ¹é…ç´¢å¼•çš„å…ƒç»„åˆ—è¡¨ã€‚
        """
        dn_match_indices = []
        idx_groups = torch.as_tensor([0, *gt_groups[:-1]]).cumsum_(0)
        for i, num_gt in enumerate(gt_groups):
            if num_gt > 0:
                gt_idx = torch.arange(end=num_gt, dtype=torch.long) + idx_groups[i]
                gt_idx = gt_idx.repeat(dn_num_group)
                assert len(dn_pos_idx[i]) == len(gt_idx), "Expected the same length, "
                f"but got {len(dn_pos_idx[i])} and {len(gt_idx)} respectively."
                dn_match_indices.append((dn_pos_idx[i], gt_idx))
            else:
                dn_match_indices.append((torch.zeros([0], dtype=torch.long), torch.zeros([0], dtype=torch.long)))
        return dn_match_indices
